{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/smithsonian.json') as f:\n",
    "    articles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tags from articles\n",
    "tags = []\n",
    "for article in articles:\n",
    "    tmp_arr = []\n",
    "    article_tags = article.get('tags', '') if article.get('tags') else ''\n",
    "    article_section = article.get('section', '') if article.get('section') else ''\n",
    "    raw_tags = article_tags + ',' + article_section\n",
    "    for tag in raw_tags.split(','):\n",
    "        normalised_tag = tag.strip().lower()\n",
    "        if normalised_tag != '':\n",
    "            tmp_arr.append(normalised_tag)\n",
    "    tags.append(' '.join(tmp_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tags to a matrix of TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate recommendations for a user given a list of tags using TF-IDF\n",
    "def tfidf_recommend(user_preference_tags, num_recommendations=5):\n",
    "    user_preference_string = ', '.join(user_preference_tags)\n",
    "    user_preference_vector = vectorizer.transform([user_preference_string])\n",
    "    similarities = cosine_similarity(user_preference_vector, tfidf_matrix)[0] # Cosine similarity return a list inside a list. We only need the first list.\n",
    "    sorted_article_indices = np.argsort(similarities)\n",
    "    top_article_indices = sorted_article_indices[-num_recommendations:]\n",
    "    return [articles[i][\"title\"] for i in top_article_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_recommend_weighted(user_model, num_recommendations=5):\n",
    "    user_preference_tags = [x['tag'] for x in user_model]\n",
    "    weights = [int(float(x['weight'])*100) for x in user_model]\n",
    "    weighted_tags = []\n",
    "    for tag, weight in zip(user_preference_tags, weights):\n",
    "        weighted_tags.extend([tag]*weight)\n",
    "    user_preference_string = ', '.join(weighted_tags)\n",
    "    user_preference_vector = vectorizer.transform([user_preference_string])\n",
    "    similarities = cosine_similarity(user_preference_vector, tfidf_matrix)[0]\n",
    "    sorted_article_indices = np.argsort(similarities)\n",
    "    top_article_indices = sorted_article_indices[-num_recommendations:]\n",
    "    return [articles[i][\"title\"] for i in top_article_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/pgrad/kanellog/Documents/AdaptiveArtemis/AdaptiveArtemisNewsRecommendation/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get BERT embeddings for a text\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create embeddings from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_with_embeddings = articles.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:46<00:00, 47.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "pbar = tqdm(total=len(articles_with_embeddings))\n",
    "# Create BERT embeddings for all articles\n",
    "for tag, article_dict in zip(tags, articles_with_embeddings):\n",
    "    embedding = get_bert_embeddings(tag)\n",
    "    article_dict[\"embedding\"] = embedding.tolist()\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/smithsonian_with_embeddings.json', 'w') as f:\n",
    "    json.dump(articles_with_embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_bert_embeddings(tags, weights):\n",
    "    weighted_embeddings = []\n",
    "    for tag, weight in zip(tags, weights):\n",
    "        tag_embedding = get_bert_embeddings(tag)\n",
    "        weighted_embedding = tag_embedding * weight\n",
    "        weighted_embeddings.append(weighted_embedding)\n",
    "    return sum(weighted_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate recommendations for a user given a list of tags\n",
    "def embeddings_recommend_weighted(user_model, article_embeddings, num_recommendations=5):\n",
    "\n",
    "    tags = [x['tag'] for x in user_model]\n",
    "    weights = [x['weight'] for x in user_model]  \n",
    "    user_tags_embeddings = get_weighted_bert_embeddings(tags, weights)\n",
    "\n",
    "    similarities = [\n",
    "        cosine_similarity(user_tags_embeddings, article_embedding)[0][0] for article_embedding in article_embeddings\n",
    "    ]\n",
    "    sorted_article_indices = np.argsort(similarities)\n",
    "    top_article_indices = sorted_article_indices[-num_recommendations:]\n",
    "    return [articles[i][\"title\"] for i in top_article_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_recommend(user_tags, article_embeddings, num_recommendations=5):\n",
    "    user_tags_embeddings = get_bert_embeddings(' '.join(user_tags))\n",
    "    similarities = [\n",
    "        cosine_similarity(user_tags_embeddings, article_embedding)[0][0] for article_embedding in article_embeddings\n",
    "    ]\n",
    "    sorted_article_indices = np.argsort(similarities)\n",
    "    top_article_indices = sorted_article_indices[-num_recommendations:]\n",
    "    return [articles[i][\"title\"] for i in top_article_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/smithsonian_with_embeddings.json') as f:\n",
    "    articles_with_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_embeddings = [np.array(article[\"embedding\"]) for article in articles_with_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = [\n",
    "    {\"tag\": \"architecture\", \"weight\": 0.5},\n",
    "    {\"tag\": \"history\", \"weight\": 0.3},\n",
    "    {\"tag\": \"art\", \"weight\": 0.9},\n",
    "    {\"tag\": \"artificial intelligence\", \"weight\": 0.1}\n",
    "]\n",
    "user_tags = [x['tag'] for x in user_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Computer Scientist Who Wants to Put a Name to Every Face in Civil War Photographs',\n",
       " 'Can Artificial Intelligence Help Stop School Shootings?',\n",
       " \"A New Encyclopedia Explores Europe's Smelly History\",\n",
       " 'With a Little Help From A.I., the Dali Museum Brings the Famed Surrealist to Life',\n",
       " 'With AI Art, Process Is More Important Than the Product']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_recommend(user_tags, num_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These Portraits Made a Bold Statement in 19th-Century America',\n",
       " 'These Wild Sculptures Could Bring Sustainable Energy to the Desert',\n",
       " \"The Striking New Artworks That Follow Rockefeller Center's Grand Tradition of Public Art\",\n",
       " 'With AI Art, Process Is More Important Than the Product',\n",
       " 'Why Museums Don’t Need Gleaming New Buildings, Especially Not in Los Angeles']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_recommend_weighted(user_model, num_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Medieval Origin Story of the Balcony',\n",
       " 'Could We Chat With Whales?',\n",
       " 'With AI Art, Process Is More Important Than the Product',\n",
       " 'From Turrets to Toilets: A Partial History of the Throne Room',\n",
       " 'The Computer Scientist Who Wants to Put a Name to Every Face in Civil War Photographs']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_recommend(user_tags, article_embeddings, num_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bye Bye Cassini, the Tenacious Space Probe That Revealed Saturn’s Secrets',\n",
       " 'Ancient Cities Lost to the Seas',\n",
       " 'The Path to Being a Scientist Doesn’t Have to Be So Narrow',\n",
       " 'In Groundbreaking Find, Three Kinds of Early Humans Unearthed Living Together in South Africa',\n",
       " 'Ancient Greece Springs to Life']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_recommend_weighted(user_model, article_embeddings, num_recommendations=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
